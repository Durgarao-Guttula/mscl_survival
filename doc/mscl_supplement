STANDARD CANDLE CALIBRATION
---------------------------

To estimate the single-cell MscL abundance from microscopy, we needed to
measure a calibration factor that could translate arbitrary fluorescence
units to protein copy number. To compute this calibration factor, we
relied on *a prior* knowledge of the mean copy number of MscL-sfGFP for
a particular bacterial strain in specific growth conditions. In
Bialecka-Fornal et al. 2012 [@bialecka-fornal2012], the average MscL
copy number for a population of cells was measured using quantitative
Western blotting and single-molecule photobleaching assays. In this
section we derive a statistical model for estimating the most-likely
value of this calibration factor and its associated error.

### Definition of a calibration factor

We assume that all detected fluorescence signal from a particular cell
is derived from the fluorescently labeled MscL protein, after correction
for autofluorescence and background subtraction. The arbitrary units of
fluorescence can be directly related to the protein copy number via a
calibration factor, $$
I_\text{tot} = \alpha N_\text{tot},
$$ where $I_\text{tot}$ is the total cell fluorescence, $N_\text{tot}$
is the total number of MscL proteins in the cell, and $\alpha$ is the
calibration factor with units of arbitrary units per protein. From
Bialecka-Fornal et al. 2012, we know the average MscL copy number of the
population rather than distribution across single cell measurements.
Knowing only the mean, we can rewrite Eq. **¿eq:ian?** as $$
\langle I_\text{tot}\rangle = \alpha \langle N_\text{tot} \rangle,
$$ assuming that $\alpha$ is a constant value that does not change from
cell to cell or fluorophore to fluorophore.

In non-synchronously growing cultures, such as in these experiments, the
cell size distribution is often broad. As described in the main text,
the cell size distribution of a population is broadened further by
modulating the MscL copy number. To speak in the terms of an effective
channel copy number, we relate the average areal intensity of the
population to the average cell size, $$
\langle I_\text{tot} \rangle = \langle \rho \rangle \langle A \rangle = \alpha \langle N_\text{tot} \rangle,
$$ where $\langle\rho\rangle$ is the average areal intensity of the
population and $\langle A \rangle$ is the average area of a segmented
cell. As only one focal plane was imaged in these experiments, we could
not compute an appropriate volume for each cell given the highly
aberrant morphology. We therefore opted to use the projected
two-dimensional area of each cell as a proxy for cell size. Given these
set of measurements, the calibration factor can be computed as $$
\alpha = {\langle \rho \rangle\langle A \rangle \over \langle N_\text{tot} \rangle}.
$$

While it is tempting to use the simple result of
Eq. **¿eq:simple\_cal\_factor?**, there are multiple sources of error
that are important to propagate through the final calculation. The most
obvious error to include is that given in Bialecka-Fornal et al. 2012
for the final channel count which represents all systematic errors in
their measurement [@bialecka-fornal2012]. There are also slight
variations in expression across biological replicates that arise from a
myriad of day-to-day differences. Rather than abstracting all sources of
error away into a systematic error budget, we used an inferential model
derived from Bayes' theorem that allows for the computation of the
probability distribution of $\alpha$.

### Estimation of $\alpha$ for a single biological replicate

A single replicate data set consists of several hundred single-cell
measurements including the areal intensity $\rho$ and the area of the
segmentation mask $A$. For this data set, we are interested in computing
the probability distributions for the calibration factor $\alpha$, the
average cell area $\langle A \rangle$, and the mean number of channels
per cell $\langle N_\text{tot} \rangle$. Using Bayes' theorem, the
posterior distribution can be written as $$
g(\alpha, \langle A \rangle, \langle N_\text{tot} \rangle\,\vert\, A, \rho) = {f(A, \rho\,\vert
\, \alpha,\langle A \rangle, \langle N_\text{tot} \rangle) g(\alpha,\langle A \rangle, \langle N_\text{tot} \rangle) \over f(\alpha, \rho)},
$$ where $g$ and $f$ represent probability density functions over
parameters and data, respectively. The term
$f(A, \rho\,\vert\, \alpha, \langle A \rangle, \langle N_\text{tot} \rangle)$
in the numerator represents the likelihood of observing the areal
intensity $\rho$ and area $A$ of a cell for a given values of $\alpha$,
$\langle A \rangle$, and $\langle N_\text{tot} \rangle$. The second term
in the numerator
$g(\alpha,\langle A \rangle, \langle N_\text{tot} \rangle)$ describes
the prior knowledge we have regarding the possible values of the the
parameters knowing nothing about the measured data. The denominator,
$f(\rho, A)$ captures the probability of observing the data knowing
nothing about the parameter values. This term, in our case, serves
simply as a normalization constant and will be neglected for the
remainder of this section.

To determine the appropriate functional form for the likelihood and
prior, we must make some assumptions about the processes that generate
them. As the cultures in these experiments are asynchronous in their
growth, we should be able to observe a relatively uniform distribution
of growth phases ranging from newborn cells to those nearly completed
with septation. As there are many independent processes that regulate
the timing of cell division and cell growth, such as DNA replication and
peptidoglycan synthesis, it is reasonable to assume that for a given
culture the distribution of cell size would be normally distributed with
a mean of $\langle A \rangle$ and a variance
$\sigma_{\langle A \rangle}$. Mathematically, we can write this as $$
f(A\,\vert\,\langle A \rangle, \sigma_{\langle A \rangle}) \propto {1 \over \sigma_{\langle A \rangle}}\exp\left[-{(A - \langle A \rangle)^2 \over 2\sigma_{\langle A \rangle}^2}\right],
$$ where the proportionality results from dropping normalization
constants for notational simplicity.

The areal intensity $\rho$ is intrinsically dependent on the cell area
$A$. However, the myriad processes leading the detected fluorescence,
such as translation and proper protein folding, are largely independent
processes, allowing us to assume a normal distribution for $\rho$ as
well with a mean $\langle \rho \rangle$ and a variance $\sigma_\rho$. To
compute the average intensity for the population $\langle \rho \rangle$
given $\langle A \rangle$ and $\langle N_\text{tot} \rangle$, we can use
Eq. **¿eq:area\_conversion?** to say $$
\rho =  {\alpha\langle N_\text{tot} \rangle \over \langle A \rangle},
$$ allowing us to write the likelihood as $$
f(\rho\,\vert\,\alpha,\langle A \rangle,\langle N_\text{tot} \rangle, \sigma_\rho) \propto {1 \over \sigma_\rho}\exp\left[-{\left(\rho - {\alpha \langle N_\text{tot} \rangle\over \langle A \rangle}\right)^2 \over 2 \sigma_\rho^2}\right].
$$

With these two likelihoods in hand, we are tasked with determining the
appropriate priors. As we have assumed normal distributions for the
likelihoods of $\langle A \rangle$ and $\rho$, we have included two
additional parameters, $\sigma_{\langle A \rangle}$ and $\sigma_\rho$,
each requiring their own prior probability distribution. It is common
practice to assume maximum ignorance for these variances and use a
Jeffreys prior [@sivia2006], $$
g(\sigma_{\langle A \rangle}, \sigma_\rho) = {1 \over \sigma_{\langle A \rangle}\sigma_\rho}.
$$

The next obvious prior to consider is for the average channel copy
number $\langle N_\text{tot} \rangle$, which comes from Bialecka-Fornal
et al. 2012. In this work, they report a mean $\mu_N$ and variance
$\sigma_N$, allowing us to assume a normal distribution for the prior,
$$
g(\langle N_\text{tot}\rangle\,\vert\, \mu_N,\sigma_N) \propto {1 \over \sigma_N}\exp\left[-{(\langle N_\text{tot} \rangle - \mu_N)^2 \over 2 \sigma_N^2}\right].
$$

For $\alpha$ and $\langle A \rangle$, we have some knowledge of what
these parameters can and cannot be. For example, we know that neither of
these parameters can be negative. As we have been careful to not
overexpose the microscopy images, we can say that the maximum value of
$\alpha$ would be the bit-depth of our camera. Similarly, it is
impossible to segment a single cell with an area larger than our
camera's field of view (although there are biological limitations to
size below this extreme). To remain maximally uninformative, we can
assume that the parameter values are uniformly distributed between these
bounds, allowing us to state $$
g(\alpha) = \begin{cases} {1 \over \alpha_\text{max} - \alpha_\text{min}} & \alpha_\text{min} \leq \alpha \leq \alpha_\text{max} \\
0 & \text{otherwise}
\end{cases},
$$ for \alpha and $$
g(\langle A \rangle) = \begin{cases} {1 \over \langle A \rangle_\text{max} - \langle A \rangle_\text{min}} & \langle A \rangle_\text{min} \leq \langle A \rangle \leq \langle A \rangle_\text{max}\\
0 & \text{otherwise}
\end{cases}
\qquad (1)$$ for $\langle A \rangle$.

Piecing Eq. **¿eq:area\_likelihood?** through
Eq. **¿eq:area\_uniform\_prior?** together generates a complete
posterior probability distribution for the parameters given a single
cell measurement. This can be generalized to a set of $k$ single cell
measurements as $$
\begin{aligned}
g(\alpha,\langle A \rangle, \langle N_\text{tot} \rangle, \sigma_\rho, \sigma_{\langle A \rangle}\,\vert\, [\rho, A], \mu_N, \sigma_N) &\propto {1 \over (\alpha_\text{max} - \alpha_\text{min})(\langle A \rangle_\text{max} - \langle A \rangle_\text{min})\sigma_{\langle A \rangle}\sigma_\rho}{1 \over (\sigma_\rho\sigma_{\langle A \rangle})^k}\,\times\\
&{1 \over \sigma_N}\exp\left[- {(\langle N_\text{tot}\rangle - \mu_N)^2 \over 2\sigma_N^2}\right]
\prod\limits_i^k\exp\left[-{(A^{(i)} - \langle A \rangle)^2 \over 2\sigma_{\langle A \rangle}^2} - {\left(\rho^{(i)} - {\alpha \langle N_\text{tot}\rangle \over \langle A \rangle}\right)^2 \over 2\sigma_\rho^2}\right] \end{aligned},
$$ where $[\rho, A]$ represents the set of $k$ single-cell measurements.

As small variations in the day-to-day details of cell growth and sample
preparation can alter the final channel count of the standard candle, it
is imperative to perform more than a single biological replicate.
However, properly propagating the error is non trivial. One option would
be to pool together all measurements of $n$ biological replicates and
evaluate the posterior given in Eq. **¿eq:single\_rep\_post?**. However,
this by definition assumes that there is no difference between
replicates. Another option would be to perform this analysis on each
biological replicate individually and then compute a mean and standard
deviation of the resulting most-likely parameter estimates. While this
is a better approach than simply pooling all data together, it suffers a
bias from giving each replicate equal weight, skewing the estimate of
the most-likely parameter value if one replicate is markedly brighter or
dimmer than the others. Given this type of data and a limited number of
biological replicates ($n = 6$ in this work), we chose to extend the
Bayesian analysis presented in this section to model the posterior
probability distribution for $\alpha$ and $\langle A \rangle$ as a
hierarchical process.

### A hierarchical model for estimating $\alpha$

In the previous section, we assumed maximally uninformative priors for
the most-likely parameter values for $\alpha$ and
$\langle N_\text{tot} \rangle$. While this is a fair approach to take
for these parameters, we are not completely ignorant for how these
values are distributed across biological replicates. A major assumption
of our model is that the most-likely value of $\alpha$ and
$\langle A \rangle$ for each biological replicate are comparable, so
long as the experimental error between them is accounted for. In other
words, we are assuming that the most-likely value for each replicate is
drawn from a global distribution. While each replicate may have a unique
value, they are all related to one another. With enough replicates, we
would be able to adequately sample this distribution by treating each
replicate independently. Unfortunately, proper sampling of this
distribution requires an extensive amount of experimental work, making
inferential approaches more attractive.

In this approach, often called a multi-level or hierarchical model, is
schematized in Fig. **¿fig:hierarchical\_model?**. Here, we use an
informative prior for $\alpha$ and $\langle A \rangle$ for each
biological replicate. This informative prior probability distribution
can be described by the summary statistics, often called
hyper-parameters, which are then used as the most-likely values for the
parameters. As this approach allows us to get a picture of the
probability distribution of the hyper-parameters, we are able to report
a point estimate and error that captures all known sources of the
statistical error.

![**Schematic of hierarchical model structure**. The hyper-parameter
probability distributions (top panel) are used as an informative prior
for the most-likely parameter values for each biological replicate
(middle panel). The single-cell measurements of cell area and areal
intensity (bottom panel) are used as data in the evaluation of the
likelihood](../figs/hierarchical_model.png){#Fig:hierarchical_model}

The choice for the functional form for the informative prior is often
not obvious and can require other experimental approaches or
back-of-the-envelope estimates to approximate. Each experiment in this
work was carefully constructed to minimize the day-to-day variation.
This involved adhering to well-controlled growth temperatures and media
composition, harvesting of cells at comparable optical densities, and
ensuring identical imaging parameters. As the experimental variation is
minimized, we can use our knowledge of the underlying biological
processes to guess at the approximate functional form. For similar
reasons presented in the previous section, cell size is controlled by a
myriad of independent processes. As each replicate is independent of
another, it is reasonable to assume a normal distribution for the
average cell area for each replicate. This normal distribution is
described by a mean $\tilde{\langle A \rangle}$ and variance
$\tilde{\sigma}_{\langle A \rangle}$. Therefore, the prior for
$\langle A \rangle$ for $n$ biological replicates can be written as $$
g(\langle A \rangle\, \vert\, \tilde{\langle A \rangle}, \tilde{\sigma}_{\langle A \rangle}) \propto {1 \over \tilde{\sigma}_{\langle A \rangle}^n}\prod\limits_{j=1}^{n}\exp\left[-{(\langle A \rangle_j - \tilde{\langle A \rangle})^2 \over 2 \tilde{\sigma}_{\langle A \rangle}^2}\right].
$$ In a similar manner, we can assume that the calibration factor for
each replicate is normally distributed with a mean $\tilde{\alpha}$ and
variance $\tilde{\sigma}_\alpha$, $$
g(\alpha\,\vert\,\tilde{\alpha}, \tilde{\sigma}_\alpha) \propto {1 \over \tilde{\sigma}_\alpha^n}\prod\limits_{j=1}^n \exp\left[-{(\alpha_j - \tilde{\alpha})^2 \over 2\tilde{\sigma}_\alpha^2}\right].
$$

With the inclusion of two more normally distributed parameters, we have
introduced four new parameters, each of which needing their own prior.
However, our knowledge of the reasonable values for the hyper-parameters
has not changed from those described for a single replicate. We can
therefore use the same maximally uninformative Jeffreys priors given in
Eq. **¿eq:Jeffreys?** for the variances and the uniform distributions
given in Eq. **¿eq:alpha\_uniform\_prior?** and
Eq. **¿eq:area\_uniform\_prior?** for the means.

Stitching all of this work together generates the full posterior
probability distribution for the best-estimate of $\alpha$ and
$\langle A \rangle$ shown in Eq. **¿eq:avg\_ian?** given $n$ replicates
of $k$ single cell measurements, $$
\begin{aligned}
g(\tilde{\alpha}, \tilde{\sigma}_\alpha, \tilde{\langle A \rangle}, \tilde{\sigma}_{\langle A \rangle}, &\{\langle N_\text{tot} \rangle, \langle A \rangle, \alpha, \sigma_\rho\}\,\vert\, [\rho, A], \mu_N, \sigma_N) \propto\\
&{1 \over (\tilde{\alpha}_\text{max} - \tilde{\alpha}_\text{min})(\tilde{\langle A \rangle}_\text{max} - \tilde{\langle A \rangle}_\text{min})\sigma_N^n(\tilde{\sigma}_\alpha\tilde{\sigma}_{\langle A \rangle})^{n + 1}}\,\times\,\\
&\prod\limits_{j=1}^n\exp\left[-{(\langle N \rangle_j^{(i)} - \mu_N)^2 \over 2\sigma_N^2} - {(\alpha_j - \tilde{\alpha})^2 \over 2\tilde{\sigma}_\alpha^2} - {(\langle A \rangle_j - \tilde{\langle A \rangle})^2 \over 2\tilde{\sigma}_{\langle A \rangle}^2}\right]\,\times\,\\ 
&{1 \over (\sigma_{\rho_j}\sigma_{\langle A \rangle_j})^{k + 1}}\prod\limits_{i=1}^{k_j}\exp\left[-{(A_j^{(i)} - \langle A \rangle_j)^2 \over 2\sigma^{(i)2}_{\langle A \rangle_j}} - {\left(\rho^{(i)}_j - {\alpha_j \langle N_\text{tot}\rangle_j \over \langle A \rangle_j}\right)\over 2\sigma_{\rho_j}^{(i)2}}\right].
\end{aligned}
$$

While Eq. **¿eq:cal\_factor\_posterior?** is not analytically solvable,
it can be easily sampled using Markov chain Monte Carlo (MCMC). The
results of the MCMC sampling for $\tilde{\alpha}$ and
$\tilde{\langle A \rangle}$ can be seen in
Fig. **¿fig:alpha\_area\_sampling?**. From this approach, we found the
most-likely parameter values of $3300^{+700}_{-700}$ a.u. per MscL
channel and $5.4^{+0.4}_{-0.5}$ $\mu$m$^2$ for $\tilde{\alpha}$ and
$\tilde{\langle A \rangle}$, respectively. Here, we've reported the
median value of the posterior distribution for each parameter with the
upper and lower bound of the 95% credible region as superscript and
subscript, respectively.

![**Posterior distributions for hyper-parameters and replicate
parameters.** (A) The posterior probability distribution for
$\tilde{\alpha}$ and $\tilde{\langle A \rangle}$. Probability increases
from light to dark red. The replicate parameter (blue) and
hyper-parameter (red) marginalized posterior probability distributions
for $\alpha$ (B) and $\langle A \rangle$
(C).](../figs/FigSX1.png){#Fig:posterior_samples} \#

LOGISTIC REGRESSION
-------------------

In this work, we were interested in computing the survival probability
under a large hypo-osmotic shock as a function of MscL channel number.
As the channel copy number distributions for each Shine-Dalgarno
sequence mutant were broad and extensively overlapping, we chose to use
a method of calculating survival probability through logistic regresion
- a method that requires no binning of the data providing the least
biased estimate of survival probability. Logistic regression is a
technique that has been used in medical statistics since the late 1950's
to describe diverse phenomena such as dose response curves, criminal
recidivism, and survival probabilities for patients after treatment. It
has also found much use in machine learning to tune a binary or
categorical response given a continuous predictor signal. (**Find
citations -- I know they are there**)

In this section, we derive a statistical model for estimating the
most-likely values for the coefficients $\beta_0$ and $\beta_1$ and use
Bayes' theorem to provide an interpretation for the statistical meaning.

### Bayesian parameter estimation of $\beta_0$ and $\beta_1$

The central challenge of this work is to estimate the probability of
survival $p_s$ given only a measure of the total number of MscL channels
in that cell. In other words, for a given measurement of $N_c$ channels,
we want to know likelihood that cell would survive a given osmotic
shock. Using Bayes' theorem we can write a statistical model for the
survival probability as $$
g(p_s\,\vert\, N_c) = {f(N_c\,\vert\, p_s)g(p_s) \over f(N_c)},
$$

where $g$ and $f$ represent probability density functions over
parameters and data, respectively. The posterior probability
distribution $g(p_s\,\vert\, N_c)$ describes the probability of $p_s$
given a specific number of channels $N_c$. This distribution is
dependent on the likelihood of observing $N_c$ channels assuming a value
of $p_s$ multiplied by all prior knowledge we have about knowing nothing
about the data, $g(s)$. The denominator $f(N_c)$ in
Eq. **¿eq:bayes\_surv\_prob?** captures all knowledge we have about the
available values of $N_c$, knowing nothing about the true survival
probability. As this term acts as a normalization constant, we will
neglect it in the following calculations for notational brevity.

To begin, we must come up with a statistical model that describes the
experimental measurable in our experiment -- survival or death. As this
is a binary response, we can consider each measurement as a Bernoulli
trial with a probability of success matching our probability of survival
$p_s$, $$
f(s\, \vert\, p_s) = p_s^s(1 - p_s)^{1-s},
$$ where $s$ is the binary response of $1$ or $0$ for survival and
death, respectively. As is stated in the introduction to this section,
we decided to use a logistic function to describe the survival
probability. We assume that the log-odds of survival is linear with
respect to the effective channel copy number $N_c$ as $$
\log{p_s \over 1 - p_s} = \beta_0 + \beta_1 N_c,
$$ where $\beta_0$ and $\beta_1$ are coefficients which describe the
survival probability in the absence of channels and the increase in
log-odds of survival conveyed by a single channel. The rationale behind
this interpretation is presented in the following section, \*A Bayesian
interpretation of $\beta_0$ and $\beta_1$. With this assumption in hand,
we can solve for $p_s$, $$
p_s = {1 \over 1 + e^{-\beta_0 -\beta_1 N_c}}.
$$

With a functional form for the survival probability, the probability of
observing $N_c$ channeles given a measurement of survival and values for
$|beta_0$ and $\beta_1$ can be stated as
$$f(N_c, s\,\vert\,\beta_0,\beta_1) = \left({1 \over 1 + e^{-\beta_0 - \beta_1 N_c}}\right)^s\left(1 - {1 \over 1 + e^{-\beta_0 - \beta_1 N_c}}\right)^{1 - s},
$$ which is the likelihood presented in Eq. **¿eq:bayes\_surv\_prob?**.
As we have now introduced two parameters, $\beta_0$, and $\beta_1$, we
must provide some description of our prior knowledge for each. As is
typically the case, we k,now nothing about the values for $\beta_0$ and
$\beta_1$. These parameters are allowed to take any value, so long as it
is a real number. Since all values are allowable, we can assume a flat
distribution for each and remove the constant from the posterior
distribution. For a set of $k$ single-cell measurements, we can write
the posterior probability distribution stated in
Eq. **¿eq:bayes\_surv\_prob?** as $$
g(\beta_0, \beta_1\,\vert\, N_c, s) = \prod\limits_{i=1}^n\left({1 \over 1 + e^{-\beta_0 - \beta_1 N_c^{(i)}}}\right)^{s^{(i)}}\left(1 - {1 \over 1 + e^{-\beta_0 - \beta_1 N_c^{(i)}}}\right)^{1 - s^{(i)}}
$$Eq. **¿eq:known\_nc\_post?**

Implicitly stated in Eq. **¿eq:known\_nc\_post?** is absolute knowledge
of the channel copy number $N_c$. However, as is described in the
section *Standard Candle Calibration*, we must convert from a measured
areal sfGFP intensity $\rho$ to a effective channel copy number, $$
N_c = {\rho \tilde{\langle A \rangle} \over \tilde{\alpha}},
$$ where $\tilde{\langle A \rangle}$ is the average cell area of the
standard candle strain and $\tilde{\alpha}$ is the most-likely value for
the calibration factor between arbitrary units and protein copy number.
Earlier in *Standard Candle Calibration*, we detailed a process for
generating an estimate for the most-likely value of
$\tilde{\langle A \rangle}$ and $\tilde{\alpha}$. Given these estimates,
we can include an informative prior for each value. From the Markov
chain Monte Carlo samples shown in
Fig. **¿fig:posterior\_distributions?**, the posterior distribution for
each parameter is approximately Gaussian. By approximating them as
Gaussian distributions, we can assign an informative prior for each as
$$
g(\alpha\,\vert\,\tilde{\alpha}, \tilde{\sigma}_\alpha) \propto {1 \over \tilde{\sigma}_\alpha^k}\prod\limits_{i=1}^k\exp\left[-{(\alpha_i - \tilde{\alpha})^2 \over  2\tilde{\sigma}_\alpha^2}\right]
$$ for the calibration factor for each cell and $$
g(\langle A \rangle\,\vert\,\tilde{\langle A \rangle},\tilde{\sigma}_{\langle A \rangle}) = {1 \over \tilde{\sigma}_{\langle A \rangle}^k}\prod\limits_{i=1}^k\exp\left[-{(\langle A \rangle_i - \tilde{\langle A \rangle})^2 \over 2\tilde{\sigma}_{\langle A \rangle}^2}\right],
$$ where $\tilde{\sigma}_\alpha$ and
$\tilde{\sigma}_{\langle A \rangle}$ represent the variance from
approximating each posterior as a Gaussian. The proportionality for each
prior arises from the neglection of normalization constants for
notational clarity.

Given \[\#Eq:bernouilli\_likelihood\] through Eq. **¿eq:area\_prior?**,
the complete posterior distribution for estimating the most likely
values of $\beta_0$ and $\beta_1$ can be written as $$
\begin{aligned}
g(\beta_0, &\beta_1\,\vert\,[\rho, s],\tilde{\langle A \rangle}, \tilde{\sigma}_{\langle A \rangle}, \tilde{\alpha}, \tilde{\sigma}_\alpha) \propto{1 \over (\tilde{\sigma}_\alpha\tilde{\sigma}_{\langle A \rangle})^k}\prod\limits_{i=1}^k\left(1 + \exp\left[-\beta_0 - \beta_1 {\rho_i \langle A \rangle_i \over \alpha_i}\right]\right)^{-s_i}\,\times\,\\
&\left(1 - \left(1 + \exp\left[-\beta_0 - \beta_1 {\rho_i\langle A \rangle_i \over \alpha_i}\right]\right)^{-1}\right)^{1 - s_i}
\exp\left[-{(\langle A \rangle_i - \tilde{\langle A \rangle})^2 \over 2\tilde{\sigma}_{\langle A \rangle}} - {(\alpha_i - \tilde{\alpha})^2\over 2\tilde{\sigma}_\alpha^2}\right]
\end{aligned}.
$$

As this posterior distribution is not solvable analytically, we used
Markov chain Monte Carlo to draw samples out of this distribution. The
posterior distributions for $\beta_0$ and $\beta_1$ for both slow and
fast shock rate data can be seen in
Fig. **¿fig:logistic\_regression\_posterior\_distributions?**

### A Bayesian interpretation of $\beta_0$ and $\beta_1$

The central challenge of this work is to estimate the probability of
survival $p_s$ given only a measure of the total number of MscL channels
in that cell. In other words, for a given measurement of $N_c$ channels,
we want to know likelihood that cell would survive a given osmotic
shock. The probability of observing a survival event $s$ given a
measurement of $N_c$ channels can be stated using Bayes' theorem as $$
g(s\,\vert\, N_c) = {f(N_c\,\vert\, s)g(s) \over f(N_c)}.
\qquad (2)$$ where $g$ and $f$ represent probability density functions
over parameters and data respectively. The posterior distribution
$g(s\,\vert\, N_c)$ is the quantity of interest and implicitly related
to the probability of survival. The likelihood $g(N_c\,\vert\, s)$ tells
us the probability of observing $N_c$ channels in this cell given that
it survives. The quantity $g(s)$ captures all *a priori* knowledge we
have regarding the probability of this cell surviving and the
denominator $f(N_c)$ tells us the converse -- the probability of
observing $N_c$ cells irrespective of the survival outcome.

Proper calculation of Eq. **¿eq:survival\_bayes?** requires that we have
knowledge of $f(N_c)$, which is difficult to estimate. While we are able
to give appropriate bounds on this term, such as a requirement of
positivity and some knowledge of the maximum membrane packing density,
it is not so obvious to determine the distribution between these bounds.
Given this difficulty, it's easier to compute the odds of survival
$\mathcal{O}(s\,\vert\, N_c)$, the probability of survival $s$ relative
to death $d$, $$
\mathcal{O}(s\,\vert\, N_c) = {g(s\,\vert\,N_c) \over g(d\,\vert\, N_c)} = {f(N_c\,\vert\, s)g(s) \over f(N_c\,\vert\,d)g(d)},
$$ where $f(N_c)$ is cancelled. The only stipulation on the possible
value of the odds is that it must be a positive value. As we would like
to equally weigh odds less than one as those of several hundred or
thousand, it is more convenient to compute the log-odds, given as $$
\log \mathcal{O}(s\,\vert\,N_c)= \log {g(s) \over g(d)} + \log {f(N_c \,\vert\, s )\over f(N_c\,\vert\, d)}.
$$ Computing the log-transform reveals two interesting quantity. The
first term is the ratio of the priors and tells us the *a priori*
knowledge of the odds of survival irrespective of the number of
channels. As we have no reason to think that survival is more likely
than death, this ratio goes to unity. The second term is the log
likelihood ratio and tells us how likely we are to observe a given
channel copy number $N_c$ given the cell survives relative to when it
dies.

For each channel copy number, we can evaluate Eq. **¿eq:log\_odds?** to
measure the log odds of survival. If we start with zero channels per
cell, we can write the log-odds as $$
\log \mathcal{O}(s\,\vert\,N_c=0) = \log {g(s) \over g(d)} + \log {f(N_c=0\,\vert\, s) \over f(N_c=0\,\vert\, d)}.
$$ For a channel copy number of one, the odds of survival is $$
\log \mathcal{O}(s\,\vert\,N_c=1) = \log{g(s) \over g(d)} + \log{f(N_c=1\,\vert\, s) \over f(N_c=1\,\vert\, d)}.
$$ In both Eq. **¿eq:nc?**=0 and Eq. **¿eq:nc?**=1, the log of our *a
priori* knowledge of survival versus death remains. The only factor that
is changing is log likelihood ratio. We can be more general in our
language and say that the log-odds of survival is increased by the
difference in the log odds between any two channel copy numbers. We can
rewrite the log likelihood ratio in a more general form as $$
\log {f(N_c\, \vert\, s) \over f(N_c\,\vert\, d)} = \log{f(N_c = 0\,\vert\,s) \over f(N_c=0\,\vert\, d)} + N_c \left[\log{f(N_c=1 \,\vert\,s) \over f(N_c=1\,\vert\, d)} - \log{f(N_c=0\,\vert\, s) \over f(N_c=0\,\vert\, d)}\right],
$$ where we are now only considering the case in which $N_c \in [0, 1]$.
The bracketed term in Eq. **¿eq:generalized\_LLR?** is the log of the
odds of survival given a single channel relative to the odds of survival
given no channels. Mathematically, this odds-ratio can be expressed as
$$
\mathcal{OR}_{N_c}(s) = {{f(N_c=0\,\vert\,s)g(s)\over f(N_c=0\,\vert\,d)g(d)}\over {f(N_c=1\,\vert\,s)g(s)\over f(N_c=1\,\vert\,d)g(d)}} = {f(N_c=0\,\vert\,s) f(N_c=1\,\vert\,d)\over f(N_c=1\,\vert s)f(N_c=0\,\vert\,d)}.
$$ The log of \[Eq:odds\_ratio\] is mathematically equivalent to the
bracketed term shown in Eq. **¿eq:generalized\_LLR?**.

We can now begin to staple these pieces together to arrive at an
expression for the log odds of survival. Combining
Eq. **¿eq:generalized\_LLR?** with Eq. **¿eq:log\_odds?** generates $$
\log \mathcal{O}(s\,\vert\,N_c) = \log{g(s) \over g(d)} + \log {f(N_c=0\,\vert\, s) \over f(N_c=0\,\vert\, d)} + N_c\left[{f(N_c=1\,\vert\,s)\over f(N_c=1\,\vert\,d)} - \log{f(N_c=0\,\vert\,s) \over f(N_c=0\,\vert\,d)}\right].
$$\[\#Eq:combined\_v1\] Using our knowledge that the bracketed term is
the log odds-ratio and the first two times represents the log-odds of
survival with $N_c=0$, we conclude with $$
\log\mathcal{O}(s\,\vert\,N_c) = \log \mathcal{O}(s\,\vert\,N_c=0) + N_c \mathcal{OR}_{N_c}(s).
$$ This result can be directly compared to Eq. 1 presented in the main
text, $$
\log {p_s \over 1 - p_s} = \beta_0 + \beta_1 N_c,
$$ which allows for an interpretation of the seemingly arbitrary
coefficients $\beta_0$ and $\beta_1$. The intercept term, $\beta_0$,
captures the log-odds of survival with no MscL channels. The slope,
$\beta_1$, describes the log odds-ratio of survival which a single
channel relative to the odds of survival with no channels at all. While
we have examined this considering only two possible channel copy numbers
($1$ and $0$), the relationship between them is linear. We can therefore
generalize this for any MscL copy number as the increase in the log-odds
of survival is constant for a change of one channel.

REFERENCES {#bibliography .unnumbered}
==========
